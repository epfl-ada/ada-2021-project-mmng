{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from helpers import *\n",
    "\n",
    "import sys\n",
    "\n",
    "import bz2\n",
    "import json\n",
    "\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "# import scipy\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "# from sklearn.linear_model import SGDClassifier\n",
    "# from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing without trunctions\n",
    "# np.set_printoptions(threshold=sys.maxsize)\n",
    "# pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO describe a bit about party labeling and how we only keep politicians!!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting which political party does a quote's message lean towards\n",
    "\n",
    "Our first task is to create a model that can classify the political inclinations of a single quote.\n",
    "\n",
    "Since, our classification task strongly resembles that of NLP sentiment analysis\n",
    "we applied a corresponding methodology.\n",
    "\n",
    "Which can be summed up by the following steps by the following steps:\n",
    "1. Label data (done in part2)\n",
    "2. Clean quotations (augmented in part3, this part)\n",
    "3. Vectorize quotations\n",
    "4. Train models and select optimal model for prediction\n",
    "\n",
    "Due to the complex nature of the task, which is to predict whether a single quote\n",
    "was said by a republican or democrat politician reaching a high accuracy is very\n",
    "difficult and so we had to optimize all the steps described above.\n",
    "\n",
    "Also, as noted in the course and on various online resources. It is sometimes\n",
    "better to have less data cleaning and text preprocessing in an\n",
    "NLP sentiment analysis tasks.\n",
    "\n",
    "We therfore had to find the optimal pipeline. This required finding the best \n",
    "combination of text preprocessor/cleaner, vectorizer and ML model. Given, that\n",
    "this isn't an ML class we tested a few computationally simple models\n",
    "(which can also be trained in a reasonable time frame) and focused rather on\n",
    "optimizing the preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the optimal level of preprocessing\n",
    "\n",
    "Our strategy in order to complete this task is to generate a dataset of quotes\n",
    "where each quote has with 5 different levels of text preprocessing, ranging \n",
    "from very light to very strong. Then we run cross validation with a few simple models \n",
    "(to keep execution time reasonable) and aggregate a few performance metrics to\n",
    "identify which level of preprocessing yielded the best performance with our model.\n",
    "\n",
    "Unlike for the final classification pipeline/model we perform all this only with \n",
    "quotes from 2020 since it is a reasonably sized snapshot of the data for this task.\n",
    "\n",
    "Each level of preprocessing was given a 1 letter name A,B,...,E.\n",
    "Here is a description of the 5 different levels of preprocessing:\n",
    "- A: Some trivial cleanup, removing digits and diacritics.\n",
    "- B: All steps in A + casefolding and removing punctuation.\n",
    "- C: All steps in B + removing stopwords.\n",
    "- D: All steps in C + stemming. Using the snowball stemmer.\n",
    "- E: All steps in C + lemmatization. Using nltk's WordNetLemmatizer.\n",
    "\n",
    "We perform the analysis in the cells below. We first prepare the data\n",
    "before running out tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(349146, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quoteID</th>\n",
       "      <th>quotation</th>\n",
       "      <th>speaker</th>\n",
       "      <th>date</th>\n",
       "      <th>numOccurrences</th>\n",
       "      <th>id</th>\n",
       "      <th>party_label</th>\n",
       "      <th>US_congress_bio_ID</th>\n",
       "      <th>quotation_cleanA</th>\n",
       "      <th>quotation_cleanB</th>\n",
       "      <th>quotation_cleanC</th>\n",
       "      <th>quotation_cleanD</th>\n",
       "      <th>quotation_cleanE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-16-000088</td>\n",
       "      <td>[ Department of Homeland Security ] was livid ...</td>\n",
       "      <td>sue myrick</td>\n",
       "      <td>2020-01-16 12:00:13</td>\n",
       "      <td>1</td>\n",
       "      <td>Q367796</td>\n",
       "      <td>R</td>\n",
       "      <td>M001134</td>\n",
       "      <td>[ Department of Homeland Security ] was livid ...</td>\n",
       "      <td>department of homeland security was livid and ...</td>\n",
       "      <td>department homeland security livid strongly ur...</td>\n",
       "      <td>depart homeland secur livid strong urg agenda ...</td>\n",
       "      <td>department homeland security livid strongly ur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-26-000499</td>\n",
       "      <td>a few of the candidates who will do better in ...</td>\n",
       "      <td>dave loebsack</td>\n",
       "      <td>2020-01-26 13:21:36</td>\n",
       "      <td>11</td>\n",
       "      <td>Q771586</td>\n",
       "      <td>D</td>\n",
       "      <td>L000565</td>\n",
       "      <td>a few of the candidates who will do better in ...</td>\n",
       "      <td>a few of the candidates who will do better in ...</td>\n",
       "      <td>candidates better part world</td>\n",
       "      <td>candid better part world</td>\n",
       "      <td>candidate better part world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-26-040663</td>\n",
       "      <td>The generational thing is important, quite hon...</td>\n",
       "      <td>dave loebsack</td>\n",
       "      <td>2020-01-26 13:21:36</td>\n",
       "      <td>11</td>\n",
       "      <td>Q771586</td>\n",
       "      <td>D</td>\n",
       "      <td>L000565</td>\n",
       "      <td>The generational thing is important, quite hon...</td>\n",
       "      <td>the generational thing is important quite hone...</td>\n",
       "      <td>generational thing important quite honestly th...</td>\n",
       "      <td>generat thing import quit honest think everyth...</td>\n",
       "      <td>generational thing important quite honestly th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-20-000982</td>\n",
       "      <td>a host of other protections</td>\n",
       "      <td>debbie lesko</td>\n",
       "      <td>2020-01-20 15:32:48</td>\n",
       "      <td>1</td>\n",
       "      <td>Q16731415</td>\n",
       "      <td>R</td>\n",
       "      <td>L000589</td>\n",
       "      <td>a host of other protections</td>\n",
       "      <td>a host of other protections</td>\n",
       "      <td>host protections</td>\n",
       "      <td>host protect</td>\n",
       "      <td>host protection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-09-060095</td>\n",
       "      <td>No, are you kidding? The way that this place l...</td>\n",
       "      <td>debbie lesko</td>\n",
       "      <td>2020-01-09 23:15:21</td>\n",
       "      <td>1</td>\n",
       "      <td>Q16731415</td>\n",
       "      <td>R</td>\n",
       "      <td>L000589</td>\n",
       "      <td>No, are you kidding? The way that this place l...</td>\n",
       "      <td>no are you kidding the way that this place lea...</td>\n",
       "      <td>kidding way place leaks around</td>\n",
       "      <td>kid way place leak around</td>\n",
       "      <td>kidding way place leak around</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             quoteID                                          quotation  \\\n",
       "0  2020-01-16-000088  [ Department of Homeland Security ] was livid ...   \n",
       "1  2020-01-26-000499  a few of the candidates who will do better in ...   \n",
       "2  2020-01-26-040663  The generational thing is important, quite hon...   \n",
       "3  2020-01-20-000982                        a host of other protections   \n",
       "4  2020-01-09-060095  No, are you kidding? The way that this place l...   \n",
       "\n",
       "         speaker                date  numOccurrences         id party_label  \\\n",
       "0     sue myrick 2020-01-16 12:00:13               1    Q367796           R   \n",
       "1  dave loebsack 2020-01-26 13:21:36              11    Q771586           D   \n",
       "2  dave loebsack 2020-01-26 13:21:36              11    Q771586           D   \n",
       "3   debbie lesko 2020-01-20 15:32:48               1  Q16731415           R   \n",
       "4   debbie lesko 2020-01-09 23:15:21               1  Q16731415           R   \n",
       "\n",
       "  US_congress_bio_ID                                   quotation_cleanA  \\\n",
       "0            M001134  [ Department of Homeland Security ] was livid ...   \n",
       "1            L000565  a few of the candidates who will do better in ...   \n",
       "2            L000565  The generational thing is important, quite hon...   \n",
       "3            L000589                        a host of other protections   \n",
       "4            L000589  No, are you kidding? The way that this place l...   \n",
       "\n",
       "                                    quotation_cleanB  \\\n",
       "0  department of homeland security was livid and ...   \n",
       "1  a few of the candidates who will do better in ...   \n",
       "2  the generational thing is important quite hone...   \n",
       "3                        a host of other protections   \n",
       "4  no are you kidding the way that this place lea...   \n",
       "\n",
       "                                    quotation_cleanC  \\\n",
       "0  department homeland security livid strongly ur...   \n",
       "1                       candidates better part world   \n",
       "2  generational thing important quite honestly th...   \n",
       "3                                   host protections   \n",
       "4                     kidding way place leaks around   \n",
       "\n",
       "                                    quotation_cleanD  \\\n",
       "0  depart homeland secur livid strong urg agenda ...   \n",
       "1                           candid better part world   \n",
       "2  generat thing import quit honest think everyth...   \n",
       "3                                       host protect   \n",
       "4                          kid way place leak around   \n",
       "\n",
       "                                    quotation_cleanE  \n",
       "0  department homeland security livid strongly ur...  \n",
       "1                        candidate better part world  \n",
       "2  generational thing important quite honestly th...  \n",
       "3                                    host protection  \n",
       "4                      kidding way place leak around  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load preprocessed data containing all variants of text processing\n",
    "path = fixpath(QUOTES_2020_LABELED_CLEANED_VARIANTS)\n",
    "# path = fixpath(QUOTES_2020_LABELED_CLEANED_VARIANTS)\n",
    "\n",
    "df_raw = pd.read_json(path, orient='records', lines=True)\n",
    "print(df_raw.shape)\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_raw.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We drop very short quotes as a quote that is particularly short will give us\n",
    "little information and would most likely be irrelevant in the classification\n",
    "task. We just drop quotes shorter than 90% of all other quotes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(311839, 13)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Droping short quotes. Quotes shorter than 90% of all other quotes\n",
    "df = drop_short_quotes(df, threshold_quantile=0.1, quote_col_name='quotation_cleanE')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "D    194756\n",
       "R    117083\n",
       "Name: party_label, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking if dataset is balanced\n",
    "df['party_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data is unbalanced. Since we have a lot of data we just downsample\n",
    "df = downsample(df, 'party_label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "D    117083\n",
       "R    117083\n",
       "Name: party_label, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking if the data is well balanced now\n",
    "df['party_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Several different sized version of the data for convenience. Since some\n",
    "# models we test take long to train. Our final prediction for best level of\n",
    "# preprocessing will be done on the full data frame (~220k quotes from 2020)\n",
    "# that we generated above.\n",
    "\n",
    "df_micro = df.sample(1000)\n",
    "df_mini = df.sample(10000)\n",
    "df = df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_classifer(df, pipeline, break_after_one_iter=False):\n",
    "    \"\"\"\n",
    "    Function to test different all version of preprocessed quotes with a given\n",
    "    classifer.\n",
    "    \"\"\"\n",
    "    \n",
    "    cols = [\n",
    "        'quotation_cleanA',\n",
    "        'quotation_cleanB',\n",
    "        'quotation_cleanC',\n",
    "        'quotation_cleanD',\n",
    "        'quotation_cleanE',\n",
    "    ]\n",
    "\n",
    "    for col in cols:\n",
    "        \n",
    "        # Get quotation preprocessing variant\n",
    "        X = df[col].values\n",
    "\n",
    "        # Get label and convert to useful format\n",
    "        y = df['party_label'].values\n",
    "        y = convert_labels(y)\n",
    "\n",
    "        # Run cross validation with different metrics\n",
    "        # scoring=['accuracy', 'precision', 'recall', 'f1']\n",
    "        scoring=['accuracy', 'f1']\n",
    "        res = cross_validate(pipeline, X, y, scoring=scoring, cv=3)\n",
    "        res.pop('score_time')\n",
    "\n",
    "        # Print results\n",
    "        print(f'Col: {col}')\n",
    "        print_cross_validate_results(res)\n",
    "        \n",
    "        if break_after_one_iter:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On each level of preprocessed text we run cross validations with 3 different ML models. \n",
    "Multinomial Naive Bayes, LogisticRegression and Gradient Boosted Trees.\n",
    "\n",
    "We only use Tfidf vectorization but test different levels of N-gram expansion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Col: quotation_cleanA\n",
      "\tfit_time             - \tavg: 3.628\tstd: 0.163\n",
      "\ttest_accuracy        - \tavg: 0.671\tstd: 0.001\n",
      "\ttest_f1              - \tavg: 0.673\tstd: 0.001\n",
      "Col: quotation_cleanB\n",
      "\tfit_time             - \tavg: 3.505\tstd: 0.100\n",
      "\ttest_accuracy        - \tavg: 0.671\tstd: 0.001\n",
      "\ttest_f1              - \tavg: 0.673\tstd: 0.001\n",
      "Col: quotation_cleanC\n",
      "\tfit_time             - \tavg: 2.122\tstd: 0.022\n",
      "\ttest_accuracy        - \tavg: 0.671\tstd: 0.002\n",
      "\ttest_f1              - \tavg: 0.671\tstd: 0.001\n",
      "Col: quotation_cleanD\n",
      "\tfit_time             - \tavg: 2.341\tstd: 0.304\n",
      "\ttest_accuracy        - \tavg: 0.662\tstd: 0.002\n",
      "\ttest_f1              - \tavg: 0.661\tstd: 0.001\n",
      "Col: quotation_cleanE\n",
      "\tfit_time             - \tavg: 2.533\tstd: 0.188\n",
      "\ttest_accuracy        - \tavg: 0.668\tstd: 0.002\n",
      "\ttest_f1              - \tavg: 0.667\tstd: 0.001\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('vect', TfidfVectorizer()),\n",
    "            ('clf', MultinomialNB()),\n",
    "        ])\n",
    "\n",
    "test_classifer(df, pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Col: quotation_cleanA\n",
      "\tfit_time             - \tavg: 10.666\tstd: 0.746\n",
      "\ttest_accuracy        - \tavg: 0.670\tstd: 0.001\n",
      "\ttest_f1              - \tavg: 0.666\tstd: 0.000\n",
      "Col: quotation_cleanB\n",
      "\tfit_time             - \tavg: 11.970\tstd: 2.888\n",
      "\ttest_accuracy        - \tavg: 0.670\tstd: 0.001\n",
      "\ttest_f1              - \tavg: 0.666\tstd: 0.000\n",
      "Col: quotation_cleanC\n",
      "\tfit_time             - \tavg: 7.622\tstd: 2.836\n",
      "\ttest_accuracy        - \tavg: 0.669\tstd: 0.001\n",
      "\ttest_f1              - \tavg: 0.665\tstd: 0.000\n",
      "Col: quotation_cleanD\n",
      "\tfit_time             - \tavg: 4.686\tstd: 0.382\n",
      "\ttest_accuracy        - \tavg: 0.664\tstd: 0.001\n",
      "\ttest_f1              - \tavg: 0.659\tstd: 0.000\n",
      "Col: quotation_cleanE\n",
      "\tfit_time             - \tavg: 5.684\tstd: 0.295\n",
      "\ttest_accuracy        - \tavg: 0.668\tstd: 0.001\n",
      "\ttest_f1              - \tavg: 0.663\tstd: 0.000\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('vect', TfidfVectorizer()),\n",
    "            ('clf', LogisticRegression(max_iter=1000)),\n",
    "        ])\n",
    "\n",
    "test_classifer(df, pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Col: quotation_cleanA\n",
      "\tfit_time             - \tavg: 157.447\tstd: 2.448\n",
      "\ttest_accuracy        - \tavg: 0.589\tstd: 0.001\n",
      "\ttest_f1              - \tavg: 0.494\tstd: 0.003\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/nf/186rd3kx35v_x13p5402wpsr0000gn/T/ipykernel_39206/2413891448.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m         ])\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtest_classifer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/nf/186rd3kx35v_x13p5402wpsr0000gn/T/ipykernel_39206/3534891979.py\u001b[0m in \u001b[0;36mtest_classifer\u001b[0;34m(df, pipeline, break_after_one_iter)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# scoring=['accuracy', 'precision', 'recall', 'f1']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'f1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'score_time'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ada/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# independent, and that it is pickle-able.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0mparallel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m     results = parallel(\n\u001b[0m\u001b[1;32m    268\u001b[0m         delayed(_fit_and_score)(\n\u001b[1;32m    269\u001b[0m             \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ada/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1047\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ada/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ada/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ada/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ada/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ada/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ada/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ada/lib/python3.8/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ada/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ada/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"passthrough\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m                 \u001b[0mfit_params_last_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ada/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m         \u001b[0;31m# fit the boosting stages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m         n_stages = self._fit_stages(\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ada/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[0;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m             \u001b[0;31m# fit next stage of trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 663\u001b[0;31m             raw_predictions = self._fit_stage(\n\u001b[0m\u001b[1;32m    664\u001b[0m                 \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ada/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[0;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m             \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresidual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m             \u001b[0;31m# update tree leaves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ada/lib/python3.8/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1313\u001b[0m         \"\"\"\n\u001b[1;32m   1314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1315\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m   1316\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1317\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ada/lib/python3.8/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    418\u001b[0m             )\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('vect', TfidfVectorizer()),\n",
    "            ('clf', GradientBoostingClassifier()),\n",
    "        ])\n",
    "\n",
    "test_classifer(df, pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Col: quotation_cleanA\n",
      "\tfit_time             - \tavg: 6.733\tstd: 0.309\n",
      "\ttest_accuracy        - \tavg: 0.674\tstd: 0.001\n",
      "\ttest_f1              - \tavg: 0.672\tstd: 0.001\n",
      "Col: quotation_cleanB\n",
      "\tfit_time             - \tavg: 5.830\tstd: 0.211\n",
      "\ttest_accuracy        - \tavg: 0.674\tstd: 0.001\n",
      "\ttest_f1              - \tavg: 0.672\tstd: 0.001\n",
      "Col: quotation_cleanC\n",
      "\tfit_time             - \tavg: 4.404\tstd: 0.248\n",
      "\ttest_accuracy        - \tavg: 0.672\tstd: 0.001\n",
      "\ttest_f1              - \tavg: 0.670\tstd: 0.000\n",
      "Col: quotation_cleanD\n",
      "\tfit_time             - \tavg: 4.410\tstd: 0.185\n",
      "\ttest_accuracy        - \tavg: 0.666\tstd: 0.001\n",
      "\ttest_f1              - \tavg: 0.664\tstd: 0.001\n",
      "Col: quotation_cleanE\n",
      "\tfit_time             - \tavg: 4.574\tstd: 0.207\n",
      "\ttest_accuracy        - \tavg: 0.669\tstd: 0.001\n",
      "\ttest_f1              - \tavg: 0.667\tstd: 0.000\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('vect', TfidfVectorizer()),\n",
    "            ('clf', LinearSVC()),\n",
    "        ])\n",
    "\n",
    "test_classifer(df, pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll try using using unigrams and bigrams!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Col: quotation_cleanA\n",
      "\tfit_time             - \tavg: 11.847\tstd: 0.019\n",
      "\ttest_accuracy        - \tavg: 0.707\tstd: 0.002\n",
      "\ttest_f1              - \tavg: 0.709\tstd: 0.002\n",
      "Col: quotation_cleanB\n",
      "\tfit_time             - \tavg: 11.856\tstd: 0.215\n",
      "\ttest_accuracy        - \tavg: 0.707\tstd: 0.002\n",
      "\ttest_f1              - \tavg: 0.709\tstd: 0.002\n",
      "Col: quotation_cleanC\n",
      "\tfit_time             - \tavg: 8.975\tstd: 0.102\n",
      "\ttest_accuracy        - \tavg: 0.716\tstd: 0.002\n",
      "\ttest_f1              - \tavg: 0.715\tstd: 0.002\n",
      "Col: quotation_cleanD\n",
      "\tfit_time             - \tavg: 8.662\tstd: 0.410\n",
      "\ttest_accuracy        - \tavg: 0.713\tstd: 0.002\n",
      "\ttest_f1              - \tavg: 0.712\tstd: 0.002\n",
      "Col: quotation_cleanE\n",
      "\tfit_time             - \tavg: 8.806\tstd: 0.152\n",
      "\ttest_accuracy        - \tavg: 0.715\tstd: 0.002\n",
      "\ttest_f1              - \tavg: 0.714\tstd: 0.002\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('vect', TfidfVectorizer(ngram_range=(1,2))),\n",
    "            ('clf', MultinomialNB()),\n",
    "        ])\n",
    "\n",
    "test_classifer(df, pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Col: quotation_cleanA\n",
      "\tfit_time             - \tavg: 28.409\tstd: 1.658\n",
      "\ttest_accuracy        - \tavg: 0.695\tstd: 0.002\n",
      "\ttest_f1              - \tavg: 0.690\tstd: 0.002\n",
      "Col: quotation_cleanB\n",
      "\tfit_time             - \tavg: 29.686\tstd: 5.530\n",
      "\ttest_accuracy        - \tavg: 0.695\tstd: 0.002\n",
      "\ttest_f1              - \tavg: 0.690\tstd: 0.002\n",
      "Col: quotation_cleanC\n",
      "\tfit_time             - \tavg: 40.314\tstd: 4.547\n",
      "\ttest_accuracy        - \tavg: 0.700\tstd: 0.002\n",
      "\ttest_f1              - \tavg: 0.694\tstd: 0.001\n",
      "Col: quotation_cleanD\n",
      "\tfit_time             - \tavg: 36.972\tstd: 4.372\n",
      "\ttest_accuracy        - \tavg: 0.699\tstd: 0.002\n",
      "\ttest_f1              - \tavg: 0.693\tstd: 0.002\n",
      "Col: quotation_cleanE\n",
      "\tfit_time             - \tavg: 43.261\tstd: 2.992\n",
      "\ttest_accuracy        - \tavg: 0.700\tstd: 0.003\n",
      "\ttest_f1              - \tavg: 0.695\tstd: 0.002\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('vect', TfidfVectorizer(ngram_range=(1,2))),\n",
    "            ('clf', LogisticRegression(max_iter=1000)),\n",
    "        ])\n",
    "\n",
    "test_classifer(df, pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Col: quotation_cleanA\n",
      "\tfit_time             - \tavg: 18.149\tstd: 1.085\n",
      "\ttest_accuracy        - \tavg: 0.708\tstd: 0.002\n",
      "\ttest_f1              - \tavg: 0.706\tstd: 0.002\n",
      "Col: quotation_cleanB\n",
      "\tfit_time             - \tavg: 17.297\tstd: 1.203\n",
      "\ttest_accuracy        - \tavg: 0.708\tstd: 0.002\n",
      "\ttest_f1              - \tavg: 0.706\tstd: 0.002\n",
      "Col: quotation_cleanC\n",
      "\tfit_time             - \tavg: 12.830\tstd: 0.049\n",
      "\ttest_accuracy        - \tavg: 0.718\tstd: 0.003\n",
      "\ttest_f1              - \tavg: 0.716\tstd: 0.002\n",
      "Col: quotation_cleanD\n",
      "\tfit_time             - \tavg: 10.893\tstd: 0.191\n",
      "\ttest_accuracy        - \tavg: 0.714\tstd: 0.003\n",
      "\ttest_f1              - \tavg: 0.712\tstd: 0.002\n",
      "Col: quotation_cleanE\n",
      "\tfit_time             - \tavg: 11.049\tstd: 0.225\n",
      "\ttest_accuracy        - \tavg: 0.717\tstd: 0.003\n",
      "\ttest_f1              - \tavg: 0.714\tstd: 0.003\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('vect', TfidfVectorizer(ngram_range=(1,2))),\n",
    "            ('clf', LinearSVC()),\n",
    "        ])\n",
    "\n",
    "test_classifer(df, pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again the best performing classifer is Multinomial Naive Bayes, its also\n",
    "the fastest one to train.\n",
    "\n",
    "How about adding trigrams too! We don't train all 3 models as training times\n",
    "get out of hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Col: quotation_cleanA\n",
      "\tfit_time             - \tavg: 28.222\tstd: 0.143\n",
      "\ttest_accuracy        - \tavg: 0.716\tstd: 0.003\n",
      "\ttest_f1              - \tavg: 0.717\tstd: 0.003\n",
      "Col: quotation_cleanB\n",
      "\tfit_time             - \tavg: 27.320\tstd: 0.790\n",
      "\ttest_accuracy        - \tavg: 0.716\tstd: 0.003\n",
      "\ttest_f1              - \tavg: 0.717\tstd: 0.003\n",
      "Col: quotation_cleanC\n",
      "\tfit_time             - \tavg: 18.252\tstd: 0.441\n",
      "\ttest_accuracy        - \tavg: 0.724\tstd: 0.002\n",
      "\ttest_f1              - \tavg: 0.721\tstd: 0.002\n",
      "Col: quotation_cleanD\n",
      "\tfit_time             - \tavg: 17.606\tstd: 0.456\n",
      "\ttest_accuracy        - \tavg: 0.722\tstd: 0.002\n",
      "\ttest_f1              - \tavg: 0.720\tstd: 0.002\n",
      "Col: quotation_cleanE\n",
      "\tfit_time             - \tavg: 17.822\tstd: 0.225\n",
      "\ttest_accuracy        - \tavg: 0.724\tstd: 0.002\n",
      "\ttest_f1              - \tavg: 0.721\tstd: 0.002\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('vect', TfidfVectorizer(ngram_range=(1,3))),\n",
    "            ('clf', MultinomialNB()),\n",
    "        ])\n",
    "\n",
    "test_classifer(df, pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Col: quotation_cleanA\n",
      "\tfit_time             - \tavg: 37.191\tstd: 1.032\n",
      "\ttest_accuracy        - \tavg: 0.718\tstd: 0.001\n",
      "\ttest_f1              - \tavg: 0.715\tstd: 0.001\n",
      "Col: quotation_cleanB\n",
      "\tfit_time             - \tavg: 32.412\tstd: 0.392\n",
      "\ttest_accuracy        - \tavg: 0.719\tstd: 0.001\n",
      "\ttest_f1              - \tavg: 0.715\tstd: 0.001\n",
      "Col: quotation_cleanC\n",
      "\tfit_time             - \tavg: 21.432\tstd: 0.398\n",
      "\ttest_accuracy        - \tavg: 0.724\tstd: 0.002\n",
      "\ttest_f1              - \tavg: 0.721\tstd: 0.002\n",
      "Col: quotation_cleanD\n",
      "\tfit_time             - \tavg: 20.245\tstd: 0.462\n",
      "\ttest_accuracy        - \tavg: 0.723\tstd: 0.002\n",
      "\ttest_f1              - \tavg: 0.720\tstd: 0.002\n",
      "Col: quotation_cleanE\n",
      "\tfit_time             - \tavg: 21.807\tstd: 1.688\n",
      "\ttest_accuracy        - \tavg: 0.724\tstd: 0.002\n",
      "\ttest_f1              - \tavg: 0.720\tstd: 0.002\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('vect', TfidfVectorizer(ngram_range=(1,3))),\n",
    "            ('clf', LinearSVC()),\n",
    "        ])\n",
    "\n",
    "test_classifer(df, pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we achieve our best accuracy of 72.4%, with both LinearSVC and MultinomialNB. Eventhough, it is a rather low score we found it to be acceptable given the difficulty of the task. After all predicting predicting the political party of a speaker based on one quote alone is quite a feat. We assume this could be further improved by using word2vec or BERT but that would be beyond the scope of this project.\n",
    "\n",
    "Later, we will also aggregate our predictions to predict the political affiliation of a speaker based on all the quotes that are attributed to them and as such we can expect a better performance there!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('vect', TfidfVectorizer(ngram_range=(1,4))),\n",
    "            ('clf', LinearSVC()),\n",
    "        ])\n",
    "\n",
    "test_classifer(df, pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('vect', TfidfVectorizer(ngram_range=(2,2))),\n",
    "            ('clf', MultinomialNB()),\n",
    "        ])\n",
    "\n",
    "test_classifer(df, pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training our model on all our dataset\n",
    "\n",
    "Now that we have established the best level of preprocessing and chosen \n",
    "a vectorizer and model we can train it on all the relevant quotebank data (6 million quotes).\n",
    "\n",
    "From now and onwards we only use our most optimal text\n",
    "cleaning/preprocessing (option E) which as mentioned before is our most thorough\n",
    "version of cleaning and includes lemmatization.\n",
    "\n",
    "We start by loading and preparing the data like we did for the preprocessed file\n",
    "that contained all the text preprocessing variants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quoteID</th>\n",
       "      <th>quotation</th>\n",
       "      <th>speaker</th>\n",
       "      <th>date</th>\n",
       "      <th>numOccurrences</th>\n",
       "      <th>id</th>\n",
       "      <th>party_label</th>\n",
       "      <th>US_congress_bio_ID</th>\n",
       "      <th>quotation_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-16-000088</td>\n",
       "      <td>[ Department of Homeland Security ] was livid ...</td>\n",
       "      <td>sue myrick</td>\n",
       "      <td>2020-01-16 12:00:13</td>\n",
       "      <td>1</td>\n",
       "      <td>Q367796</td>\n",
       "      <td>R</td>\n",
       "      <td>M001134</td>\n",
       "      <td>department homeland security livid strongly ur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-26-000499</td>\n",
       "      <td>a few of the candidates who will do better in ...</td>\n",
       "      <td>dave loebsack</td>\n",
       "      <td>2020-01-26 13:21:36</td>\n",
       "      <td>11</td>\n",
       "      <td>Q771586</td>\n",
       "      <td>D</td>\n",
       "      <td>L000565</td>\n",
       "      <td>candidate better part world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-26-040663</td>\n",
       "      <td>The generational thing is important, quite hon...</td>\n",
       "      <td>dave loebsack</td>\n",
       "      <td>2020-01-26 13:21:36</td>\n",
       "      <td>11</td>\n",
       "      <td>Q771586</td>\n",
       "      <td>D</td>\n",
       "      <td>L000565</td>\n",
       "      <td>generational thing important quite honestly th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-20-000982</td>\n",
       "      <td>a host of other protections</td>\n",
       "      <td>debbie lesko</td>\n",
       "      <td>2020-01-20 15:32:48</td>\n",
       "      <td>1</td>\n",
       "      <td>Q16731415</td>\n",
       "      <td>R</td>\n",
       "      <td>L000589</td>\n",
       "      <td>host protection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-09-060095</td>\n",
       "      <td>No, are you kidding? The way that this place l...</td>\n",
       "      <td>debbie lesko</td>\n",
       "      <td>2020-01-09 23:15:21</td>\n",
       "      <td>1</td>\n",
       "      <td>Q16731415</td>\n",
       "      <td>R</td>\n",
       "      <td>L000589</td>\n",
       "      <td>kidding way place leak around</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349141</th>\n",
       "      <td>2020-02-10-100845</td>\n",
       "      <td>We're just worried about making sure we keep t...</td>\n",
       "      <td>sherrie sprenger</td>\n",
       "      <td>2020-02-10 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>Q7495360</td>\n",
       "      <td>R</td>\n",
       "      <td>None</td>\n",
       "      <td>worried making sure keep balance expression ri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349142</th>\n",
       "      <td>2020-03-16-079753</td>\n",
       "      <td>We've all embraced strict proper hygiene proce...</td>\n",
       "      <td>robert abrams</td>\n",
       "      <td>2020-03-16 12:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>Q2156314</td>\n",
       "      <td>D</td>\n",
       "      <td>None</td>\n",
       "      <td>embraced strict proper hygiene procedure heard...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349143</th>\n",
       "      <td>2020-01-13-091997</td>\n",
       "      <td>What's important is that we keep moving forward.</td>\n",
       "      <td>laurie jinkins</td>\n",
       "      <td>2020-01-13 19:51:15</td>\n",
       "      <td>1</td>\n",
       "      <td>Q6501617</td>\n",
       "      <td>D</td>\n",
       "      <td>None</td>\n",
       "      <td>important keep moving forward</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349144</th>\n",
       "      <td>2020-02-20-093793</td>\n",
       "      <td>When they want a bill, they bring the bill to ...</td>\n",
       "      <td>j.t. wilcox</td>\n",
       "      <td>2020-02-20 22:12:45</td>\n",
       "      <td>1</td>\n",
       "      <td>Q6104393</td>\n",
       "      <td>R</td>\n",
       "      <td>None</td>\n",
       "      <td>want bill bring bill floor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349145</th>\n",
       "      <td>2020-02-09-057933</td>\n",
       "      <td>Who will respect different types of people, di...</td>\n",
       "      <td>susan wild</td>\n",
       "      <td>2020-02-09 15:08:23</td>\n",
       "      <td>1</td>\n",
       "      <td>Q58323072</td>\n",
       "      <td>D</td>\n",
       "      <td>W000826</td>\n",
       "      <td>respect different type people different opinio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>349146 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  quoteID                                          quotation  \\\n",
       "0       2020-01-16-000088  [ Department of Homeland Security ] was livid ...   \n",
       "1       2020-01-26-000499  a few of the candidates who will do better in ...   \n",
       "2       2020-01-26-040663  The generational thing is important, quite hon...   \n",
       "3       2020-01-20-000982                        a host of other protections   \n",
       "4       2020-01-09-060095  No, are you kidding? The way that this place l...   \n",
       "...                   ...                                                ...   \n",
       "349141  2020-02-10-100845  We're just worried about making sure we keep t...   \n",
       "349142  2020-03-16-079753  We've all embraced strict proper hygiene proce...   \n",
       "349143  2020-01-13-091997   What's important is that we keep moving forward.   \n",
       "349144  2020-02-20-093793  When they want a bill, they bring the bill to ...   \n",
       "349145  2020-02-09-057933  Who will respect different types of people, di...   \n",
       "\n",
       "                 speaker                date  numOccurrences         id  \\\n",
       "0             sue myrick 2020-01-16 12:00:13               1    Q367796   \n",
       "1          dave loebsack 2020-01-26 13:21:36              11    Q771586   \n",
       "2          dave loebsack 2020-01-26 13:21:36              11    Q771586   \n",
       "3           debbie lesko 2020-01-20 15:32:48               1  Q16731415   \n",
       "4           debbie lesko 2020-01-09 23:15:21               1  Q16731415   \n",
       "...                  ...                 ...             ...        ...   \n",
       "349141  sherrie sprenger 2020-02-10 00:00:00               1   Q7495360   \n",
       "349142     robert abrams 2020-03-16 12:00:00               2   Q2156314   \n",
       "349143    laurie jinkins 2020-01-13 19:51:15               1   Q6501617   \n",
       "349144       j.t. wilcox 2020-02-20 22:12:45               1   Q6104393   \n",
       "349145        susan wild 2020-02-09 15:08:23               1  Q58323072   \n",
       "\n",
       "       party_label US_congress_bio_ID  \\\n",
       "0                R            M001134   \n",
       "1                D            L000565   \n",
       "2                D            L000565   \n",
       "3                R            L000589   \n",
       "4                R            L000589   \n",
       "...            ...                ...   \n",
       "349141           R               None   \n",
       "349142           D               None   \n",
       "349143           D               None   \n",
       "349144           R               None   \n",
       "349145           D            W000826   \n",
       "\n",
       "                                          quotation_clean  \n",
       "0       department homeland security livid strongly ur...  \n",
       "1                             candidate better part world  \n",
       "2       generational thing important quite honestly th...  \n",
       "3                                         host protection  \n",
       "4                           kidding way place leak around  \n",
       "...                                                   ...  \n",
       "349141  worried making sure keep balance expression ri...  \n",
       "349142  embraced strict proper hygiene procedure heard...  \n",
       "349143                      important keep moving forward  \n",
       "349144                         want bill bring bill floor  \n",
       "349145  respect different type people different opinio...  \n",
       "\n",
       "[349146 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = fixpath(QUOTES_LABELED_CLEANED)\n",
    "# path = fixpath(QUOTES_2020_LABELED_CLEANED)\n",
    "df_raw = pd.read_json(path, orient='records', lines=True)\n",
    "df_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping unneeded columns and again we drop short quotes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quoteID</th>\n",
       "      <th>quotation</th>\n",
       "      <th>speaker</th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>party_label</th>\n",
       "      <th>quotation_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-16-000088</td>\n",
       "      <td>[ Department of Homeland Security ] was livid ...</td>\n",
       "      <td>sue myrick</td>\n",
       "      <td>2020-01-16 12:00:13</td>\n",
       "      <td>Q367796</td>\n",
       "      <td>R</td>\n",
       "      <td>department homeland security livid strongly ur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-26-000499</td>\n",
       "      <td>a few of the candidates who will do better in ...</td>\n",
       "      <td>dave loebsack</td>\n",
       "      <td>2020-01-26 13:21:36</td>\n",
       "      <td>Q771586</td>\n",
       "      <td>D</td>\n",
       "      <td>candidate better part world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-26-040663</td>\n",
       "      <td>The generational thing is important, quite hon...</td>\n",
       "      <td>dave loebsack</td>\n",
       "      <td>2020-01-26 13:21:36</td>\n",
       "      <td>Q771586</td>\n",
       "      <td>D</td>\n",
       "      <td>generational thing important quite honestly th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-20-000982</td>\n",
       "      <td>a host of other protections</td>\n",
       "      <td>debbie lesko</td>\n",
       "      <td>2020-01-20 15:32:48</td>\n",
       "      <td>Q16731415</td>\n",
       "      <td>R</td>\n",
       "      <td>host protection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-09-060095</td>\n",
       "      <td>No, are you kidding? The way that this place l...</td>\n",
       "      <td>debbie lesko</td>\n",
       "      <td>2020-01-09 23:15:21</td>\n",
       "      <td>Q16731415</td>\n",
       "      <td>R</td>\n",
       "      <td>kidding way place leak around</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349141</th>\n",
       "      <td>2020-02-10-100845</td>\n",
       "      <td>We're just worried about making sure we keep t...</td>\n",
       "      <td>sherrie sprenger</td>\n",
       "      <td>2020-02-10 00:00:00</td>\n",
       "      <td>Q7495360</td>\n",
       "      <td>R</td>\n",
       "      <td>worried making sure keep balance expression ri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349142</th>\n",
       "      <td>2020-03-16-079753</td>\n",
       "      <td>We've all embraced strict proper hygiene proce...</td>\n",
       "      <td>robert abrams</td>\n",
       "      <td>2020-03-16 12:00:00</td>\n",
       "      <td>Q2156314</td>\n",
       "      <td>D</td>\n",
       "      <td>embraced strict proper hygiene procedure heard...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349143</th>\n",
       "      <td>2020-01-13-091997</td>\n",
       "      <td>What's important is that we keep moving forward.</td>\n",
       "      <td>laurie jinkins</td>\n",
       "      <td>2020-01-13 19:51:15</td>\n",
       "      <td>Q6501617</td>\n",
       "      <td>D</td>\n",
       "      <td>important keep moving forward</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349144</th>\n",
       "      <td>2020-02-20-093793</td>\n",
       "      <td>When they want a bill, they bring the bill to ...</td>\n",
       "      <td>j.t. wilcox</td>\n",
       "      <td>2020-02-20 22:12:45</td>\n",
       "      <td>Q6104393</td>\n",
       "      <td>R</td>\n",
       "      <td>want bill bring bill floor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349145</th>\n",
       "      <td>2020-02-09-057933</td>\n",
       "      <td>Who will respect different types of people, di...</td>\n",
       "      <td>susan wild</td>\n",
       "      <td>2020-02-09 15:08:23</td>\n",
       "      <td>Q58323072</td>\n",
       "      <td>D</td>\n",
       "      <td>respect different type people different opinio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>349146 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  quoteID                                          quotation  \\\n",
       "0       2020-01-16-000088  [ Department of Homeland Security ] was livid ...   \n",
       "1       2020-01-26-000499  a few of the candidates who will do better in ...   \n",
       "2       2020-01-26-040663  The generational thing is important, quite hon...   \n",
       "3       2020-01-20-000982                        a host of other protections   \n",
       "4       2020-01-09-060095  No, are you kidding? The way that this place l...   \n",
       "...                   ...                                                ...   \n",
       "349141  2020-02-10-100845  We're just worried about making sure we keep t...   \n",
       "349142  2020-03-16-079753  We've all embraced strict proper hygiene proce...   \n",
       "349143  2020-01-13-091997   What's important is that we keep moving forward.   \n",
       "349144  2020-02-20-093793  When they want a bill, they bring the bill to ...   \n",
       "349145  2020-02-09-057933  Who will respect different types of people, di...   \n",
       "\n",
       "                 speaker                date         id party_label  \\\n",
       "0             sue myrick 2020-01-16 12:00:13    Q367796           R   \n",
       "1          dave loebsack 2020-01-26 13:21:36    Q771586           D   \n",
       "2          dave loebsack 2020-01-26 13:21:36    Q771586           D   \n",
       "3           debbie lesko 2020-01-20 15:32:48  Q16731415           R   \n",
       "4           debbie lesko 2020-01-09 23:15:21  Q16731415           R   \n",
       "...                  ...                 ...        ...         ...   \n",
       "349141  sherrie sprenger 2020-02-10 00:00:00   Q7495360           R   \n",
       "349142     robert abrams 2020-03-16 12:00:00   Q2156314           D   \n",
       "349143    laurie jinkins 2020-01-13 19:51:15   Q6501617           D   \n",
       "349144       j.t. wilcox 2020-02-20 22:12:45   Q6104393           R   \n",
       "349145        susan wild 2020-02-09 15:08:23  Q58323072           D   \n",
       "\n",
       "                                          quotation_clean  \n",
       "0       department homeland security livid strongly ur...  \n",
       "1                             candidate better part world  \n",
       "2       generational thing important quite honestly th...  \n",
       "3                                         host protection  \n",
       "4                           kidding way place leak around  \n",
       "...                                                   ...  \n",
       "349141  worried making sure keep balance expression ri...  \n",
       "349142  embraced strict proper hygiene procedure heard...  \n",
       "349143                      important keep moving forward  \n",
       "349144                         want bill bring bill floor  \n",
       "349145  respect different type people different opinio...  \n",
       "\n",
       "[349146 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_raw.copy()\n",
    "df.drop(['numOccurrences','US_congress_bio_ID'], axis=1, inplace=True)\n",
    "df = drop_short_quotes(df, 0.1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "D    194756\n",
       "R    117083\n",
       "Name: party_label, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['party_label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rebalance the data by downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = downsample(df, 'party_label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "D    117083\n",
       "R    117083\n",
       "Name: party_label, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['party_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bcp = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_mini = df_filt.sample(100000)\n",
    "# df_mini = df_filt.sample(frac=1)\n",
    "\n",
    "# df\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['quotation_clean'].values\n",
    "\n",
    "y = df['party_label'].values\n",
    "y = convert_labels(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "split_frac = 0.9\n",
    "\n",
    "bound = round(len(X)*split_frac)\n",
    "\n",
    "X_train = X[:bound]\n",
    "y_train = y[:bound]\n",
    "\n",
    "X_test = X[bound:]\n",
    "y_test = y[bound:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90000,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_with_file(X, vectorizer):\n",
    "    path_temp = TEMP_FILE\n",
    "\n",
    "    with open(path_temp, 'w') as d_file:\n",
    "        d_file.writelines(X + '\\n')\n",
    "\n",
    "    with open(path_temp, 'r') as s_file:\n",
    "        X_vect=vectorizer.fit_transform(s_file)\n",
    "\n",
    "    return X_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize by writing to file\n",
    "# vectorizer=TfidfVectorizer(ngram_range=(1,3))\n",
    "# X_vect = vectorize_with_file(X_train, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize in memory\n",
    "vectorizer=TfidfVectorizer()\n",
    "X_vect = vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(TEMP_FOLDER + 'quotes_vectorized_ngram=(1,3).pkl', 'wb') as file:\n",
    "#     pickle.dump(X_vect, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_vect = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90000, 29034)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_vect.shape"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c6809d3f7e90e77d8ec96c72c39a08b2522313d47c0f1d91518fdbbaf790b394"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('ada': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
